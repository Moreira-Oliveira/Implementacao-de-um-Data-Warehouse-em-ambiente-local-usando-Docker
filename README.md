# GovernanÃ§a-e-Data-Quality-com-Great-Expectations

ğŸ“š Neste projeto vamos estudar um importante tema no universo dos Data Warehouses: a governanÃ§a de dados atravÃ©s dos testes de qualidade.

ğŸ§© O que Ã© governanÃ§a de dados?

GovernanÃ§a de Dados Ã© um conjunto de processos, polÃ­ticas, normas e responsabilidades que visam garantir a qualidade, seguranÃ§a, integridade e uso adequado dos dados em uma organizaÃ§Ã£o.

Ela estabelece quem pode acessar, modificar, compartilhar ou excluir dados, alÃ©m de definir padrÃµes para sua coleta, armazenamento e anÃ¡lise.

ğŸ›  Principais Objetivos da GovernanÃ§a de Dados:

1. Qualidade dos Dados â€“ Garantir que os dados sejam precisos, consistentes e confiÃ¡veis.

2. Conformidade â€“ Cumprir leis e regulamentos (como LGPD, GDPR).

3. SeguranÃ§a â€“ Proteger dados contra vazamentos e acessos nÃ£o autorizados.

4. EficiÃªncia â€“ Melhorar a tomada de decisÃ£o com dados bem gerenciados.

5. Responsabilidade â€“ Definir papÃ©is (como DPO, stewards de dados) para supervisionar os dados.


ğŸ§© O que Ã© qualidade de dados (data quality)

Qualidade de dados (data quality) Ã© a medida de quÃ£o adequados os dados sÃ£o para seu uso pretendido, ou seja, se eles sÃ£o precisos, completos, consistentes, atualizados, vÃ¡lidos e disponÃ­veis quando necessÃ¡rios.

ğŸ›  Principais dimensÃµes da qualidade de dados:

1. PrecisÃ£o
   
Os dados refletem corretamente a realidade?

2. Completude
   
Todos os campos essenciais estÃ£o preenchidos?

3. ConsistÃªncia
   
Os dados sÃ£o coerentes entre diferentes sistemas ou registros?

4. AtualizaÃ§Ã£o
   
Os dados estÃ£o atualizados e disponÃ­veis no tempo certo?

5. Validade
   
Os dados seguem os formatos e regras definidos?

6. Unicidade

NÃ£o hÃ¡ duplicaÃ§Ãµes desnecessÃ¡rias?


ğŸ§© O que Ã© e quando usamos a ferramenta Great Expectations?

A ferramenta Great Expectations Ã© uma plataforma de validaÃ§Ã£o de qualidade de dados automatizada. Ela permite que vocÃª crie testes automatizados para verificar se os dados estÃ£o corretos, completos, consistentes, vÃ¡lidos, etc. antes de usÃ¡-los em relatÃ³rios, anÃ¡lises ou cargas de dados (ETL/ELT).

ğŸ›  Quando usar o Great Expectations?

Use quando vocÃª precisa de:

1. ValidaÃ§Ã£o automatizada de dados
   
Antes de carregar dados em um data warehouse ou alimentar dashboards, valide se os dados estÃ£o corretos.

2. Testes em pipelines de dados (ETL/ELT)
   
Integre com Airflow, dbt, Dagster, Prefect, etc., para interromper o pipeline se houver erro.

3. Auditoria e rastreabilidade (Data Quality Checks)
   
Gere documentaÃ§Ã£o automÃ¡tica sobre as regras de qualidade e os resultados dos testes.

4. DetecÃ§Ã£o precoce de anomalias
   
Encontre valores inesperados antes que causem problemas em relatÃ³rios ou decisÃµes.


ğŸ”§ Programas que irei utilizar:

âœ… Grrreat Expectations

âœ… Docker

âœ… Anaconda Python

âœ… PgAdmin


ğŸ“š Vamos comeÃ§ar o projeto com os arquivos da qualidade de dados:

![image](https://github.com/user-attachments/assets/4a9d0872-5a1f-49e2-928f-6f45bad7ebdc)

ğŸ§© Este script estÃ¡ utilizando a biblioteca Great Expectations (GX) para realizar validaÃ§Ãµes de qualidade de dados em um arquivo CSV chamado dataset.csv.

ğŸ” Pontos-Chave:

1. ValidaÃ§Ã£o Estrutural

* Verificou a existÃªncia da coluna id, a contagem de colunas (1â€“3) e linhas (1â€“100).

2. ValidaÃ§Ã£o de ConteÃºdo

* Confirmou que os valores de id sÃ£o Ãºnicos, nÃ£o nulos e estÃ£o entre 1 e 10.

3. DocumentaÃ§Ã£o e Auditoria

* Salvou as expectativas em um "expectation suite" para reuso.

* Gerou um relatÃ³rio detalhado (HTML) com resultados das validaÃ§Ãµes.

4. AutomaÃ§Ã£o

* Usou um checkpoint (dsa_checkpoint) para executar todas as validaÃ§Ãµes de forma reproduzÃ­vel.

ğŸ” Resultado Final:

* Se Resultado da AnÃ¡lise: True â†’ Todos os critÃ©rios foram atendidos.

* Se False â†’ Alguma expectativa falhou (ex.: id fora do intervalo ou duplicado), exigindo correÃ§Ã£o nos dados ou ajuste nas regras.

ğŸ” Por que isso Ã© importante?

* Evita erros em anÃ¡lises ou processos downstream (ex.: relatÃ³rios com dados inconsistentes).

* Reduz riscos de conformidade (ex.: violaÃ§Ã£o de LGPD por dados duplicados).

* Economiza tempo com validaÃ§Ãµes automatizadas em vez de verificaÃ§Ãµes manuais.

ğŸ” PrÃ³ximos Passos:

* Adapte as expectativas para outros datasets (ex.: validar e-mails, CPFs, datas).

* Integre o script a um pipeline de dados (ex.: Airflow, Prefect) para validaÃ§Ãµes contÃ­nuas.

Em resumo, o GX transforma qualidade de dados de um desafio manual em um processo confiÃ¡vel, escalÃ¡vel e documentado.


ğŸ“š Agora vamos executar, navegar atÃ© a pasta onde estÃ¡ salvo e instalar o pacote pelo prompt de comando do Anaconda Python, e iniciar o Python dataquality.py diretamente pelo navegador web.

![Image](https://github.com/user-attachments/assets/a7c3c86f-f61b-47fc-9ad9-07ad0ed09059)

ğŸ§© Calculando as metricas:

![image](https://github.com/user-attachments/assets/27012703-a9bb-4392-a495-22f751bf22d2)


ğŸ§© Resultado da anÃ¡lise:

![Image](https://github.com/user-attachments/assets/8a1974f3-714f-4d39-8f43-c31f36e3496e)


ğŸ§© Table Level Expectations:

![Image](https://github.com/user-attachments/assets/1613d8e3-05ed-4fd3-b4c6-d5d9475de095)


ğŸ“š  Processo de GovernanÃ§a e Qualidade de Dados no Data Warehouse

Aqui vamos construir uma das principais etapas do processo de governanÃ§a de dados: o processo de validaÃ§Ã£o da qualidade dos dados. E faremos isso trabalhando com o Great Expectations, ferramenta que permite automatizar a validaÃ§Ã£o de expectativas e checagem de regras de negÃ³cio. Primeiro vamos preparar o Docker (script e comandos na pasta do projeto).

![Image](https://github.com/user-attachments/assets/1af29bc1-aa92-423c-9172-fba3b8c1c7b0)


Feito isso, vamos para o PgAdmin registrar o servidor e executar os dois scripts para criar o DW, com suas dimensÃµes e a tabela fato:

![Image](https://github.com/user-attachments/assets/d76f76e9-ade8-4d05-8ff7-e739177e6d42)


Agora vamos trabalhar com os scripts Python que farÃ£o a checagem de qualidade de dados no Data Warehouse

![Image](https://github.com/user-attachments/assets/6d6adcfd-1e41-4070-9d3c-09a990464bba)


ğŸ”§ Configurando a conexÃ£o ao SGBD com linguagem Python (lab4.py, 02-modelo-fisico-prrojeto1.sql e 03-processo_etl.sql)

Este script implementa um processo completo de validaÃ§Ã£o de qualidade de dados em um Data Warehouse com PostgreSQL, utilizando a biblioteca Great Expectations. Ele Ã© um exemplo prÃ¡tico de governanÃ§a de dados aplicada, onde a consistÃªncia, completude e conformidade dos dados sÃ£o verificadas antes de serem utilizados para anÃ¡lise ou tomada de decisÃ£o.

ğŸ” O que estÃ¡ acontecendo no script:

1. ConexÃ£o com o PostgreSQL:

* O script define a string de conexÃ£o e configura o datasource do banco de dados no Great Expectations.
  

2. CriaÃ§Ã£o de um processo de validaÃ§Ã£o genÃ©rico:

* Uma funÃ§Ã£o (dsa_valida_expectativas) Ã© criada para aplicar conjuntos de expectativas a qualquer tabela do schema dw (Data Warehouse).

* A validaÃ§Ã£o retorna o resultado e gera um relatÃ³rio em HTML.
  

3. ValidaÃ§Ãµes especÃ­ficas por tabela:

ğŸ”¹ SÃ£o definidas expectativas (regras) para as seguintes tabelas:

* dim_produto

* dim_canal

* dim_cliente

* fato_venda

ğŸ”¹ Exemplos de expectativas:

* Verificar existÃªncia de colunas.

* Garantir valores nÃ£o nulos.

* Garantir unicidade de valores (como chaves primÃ¡rias).

* Validar faixas de valores (quantidade entre 1 e 1000).

* Verificar domÃ­nios de valores (por exemplo, categorias vÃ¡lidas ou tipos de clientes).
  

4. GeraÃ§Ã£o de relatÃ³rios de validaÃ§Ã£o:

* Um relatÃ³rio em formato HTML Ã© gerado para cada tabela, com os resultados das validaÃ§Ãµes â€” Ãºtil para auditoria e acompanhamento visual da qualidade.


ğŸ§© Hora de executar os arquivos:

![Image](https://github.com/user-attachments/assets/411fa0e3-8b12-4b4e-a752-dc41b97a8917)


* E entÃ£o executar o laboratÃ³rio ou script da Lab:

![Image](https://github.com/user-attachments/assets/b78d441a-f327-49b7-b24c-de77cd9aede9)

* GeraÃ§Ã£o de relatÃ³rios:

![Image](https://github.com/user-attachments/assets/3dc73a42-83bb-405e-ba00-0dd1bbf33f8d)

![Image](https://github.com/user-attachments/assets/1adfc802-524d-4e0d-939a-b7e54638e26a)


âœ… ConclusÃ£o

Neste projeto, exploramos como a governanÃ§a e a qualidade de dados sÃ£o pilares fundamentais em ambientes de Data Warehouse. Utilizando ferramentas modernas como o Great Expectations, mostramos na prÃ¡tica como automatizar testes, garantir conformidade com regras de negÃ³cio e aumentar a confiabilidade dos dados.

Ao transformar processos manuais em validaÃ§Ãµes automatizadas, ganhamos eficiÃªncia, reduzimos riscos e criamos uma base sÃ³lida para anÃ¡lises e decisÃµes estratÃ©gicas. Essa abordagem Ã© essencial para qualquer organizaÃ§Ã£o que deseje escalar suas operaÃ§Ãµes de dados com seguranÃ§a e qualidade.




